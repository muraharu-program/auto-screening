"""
ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
  - Yahoo!ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹(æ—¥æœ¬)ã‹ã‚‰éŠ˜æŸ„åˆ¥ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’å–å¾—
  - Gemini API ã§ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰ç›®ç·šã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’ 1-5 ã§åˆ¤å®š
  - ã‚¹ã‚³ã‚¢ 4 ä»¥ä¸Šã®éŠ˜æŸ„ã®ã¿ã‚’æœ€çµ‚é€šçŸ¥ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™

å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
  pip install feedparser google-generativeai requests beautifulsoup4
"""
import sys
import os
import re
import json
import time
from datetime import datetime, timedelta

sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

import pandas as pd
import numpy as np

# --- ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ä¾å­˜ ---------------------------------------------------
try:
    import feedparser
except ImportError:
    feedparser = None
    print("è­¦å‘Š: feedparser ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install feedparser ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    requests = None
    BeautifulSoup = None
    print("è­¦å‘Š: requests / beautifulsoup4 ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚")

try:
    import google.generativeai as genai
except ImportError:
    genai = None
    print("è­¦å‘Š: google-generativeai ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚pip install google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

from config import (
    GEMINI_API_KEY,
    GEMINI_MODEL,
    SENTIMENT_TOP_N,
    SENTIMENT_MIN_SCORE,
    SENTIMENT_DEFAULT_SCORE,
    SENTIMENT_API_SLEEP,
    NEWS_LOOKBACK_DAYS,
)


# ====================================================================== #
#  1. ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—å–å¾—
# ====================================================================== #

def _ticker_to_code(ticker: str) -> str:
    """
    '7203.T' â†’ '7203' ã®ã‚ˆã†ã«æœ«å°¾ã® .T ã‚’é™¤å»ã—ã¦è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™ã€‚
    """
    return ticker.replace(".T", "").replace(".t", "")


def fetch_news_rss(ticker: str, lookback_days: int = None) -> list[str]:
    """
    Yahoo!ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹(æ—¥æœ¬)ã®éŠ˜æŸ„åˆ¥ãƒ‹ãƒ¥ãƒ¼ã‚¹ RSS ã‹ã‚‰
    ç›´è¿‘ lookback_days æ—¥åˆ†ã®è¦‹å‡ºã—ã‚’å–å¾—ã™ã‚‹ã€‚

    Parameters
    ----------
    ticker : str  ä¾‹: '7203.T'
    lookback_days : int  é¡ã‚Šæ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.NEWS_LOOKBACK_DAYSï¼‰

    Returns
    -------
    list[str]  ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã®ãƒªã‚¹ãƒˆï¼ˆç©ºãƒªã‚¹ãƒˆã®å ´åˆã‚ã‚Šï¼‰
    """
    if lookback_days is None:
        lookback_days = NEWS_LOOKBACK_DAYS

    code = _ticker_to_code(ticker)
    headlines: list[str] = []

    # --- æ–¹æ³• 1: RSS ãƒ•ã‚£ãƒ¼ãƒ‰ (feedparser) ---
    if feedparser is not None:
        try:
            rss_url = f"https://finance.yahoo.co.jp/rss/company/{code}"
            feed = feedparser.parse(rss_url)
            cutoff = datetime.now() - timedelta(days=lookback_days)
            for entry in feed.entries:
                # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
                published = entry.get("published_parsed") or entry.get("updated_parsed")
                if published:
                    pub_dt = datetime(*published[:6])
                    if pub_dt < cutoff:
                        continue
                title = entry.get("title", "").strip()
                if title:
                    headlines.append(title)
        except Exception as e:
            print(f"  RSS å–å¾—ã‚¨ãƒ©ãƒ¼ ({ticker}): {e}")

    # --- æ–¹æ³• 2: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ â€” HTML ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ---
    if not headlines and requests is not None and BeautifulSoup is not None:
        try:
            page_url = f"https://finance.yahoo.co.jp/quote/{code}.T/news"
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/120.0.0.0 Safari/537.36"
                ),
            }
            resp = requests.get(page_url, headers=headers, timeout=15)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "lxml")

            # Yahoo!ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ãƒªãƒ³ã‚¯ã‚’æ¢ç´¢
            # ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã¯ DOM å¤‰æ›´ã«ä¼´ã„èª¿æ•´ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹
            for a_tag in soup.select("a[href*='/news/']"):
                text = a_tag.get_text(strip=True)
                if text and len(text) > 5:
                    headlines.append(text)

            # é‡è¤‡æ’é™¤
            headlines = list(dict.fromkeys(headlines))
        except Exception as e:
            print(f"  HTML ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ ({ticker}): {e}")

    return headlines


# ====================================================================== #
#  2. Gemini API ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ¤å®š
# ====================================================================== #

_SENTIMENT_PROMPT_TEMPLATE = """\
ã‚ãªãŸã¯æ—¥æœ¬æ ªã®ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆæ•°æ—¥ã€œ2é€±é–“ï¼‰ã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã¯éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ {ticker} ã«é–¢ã™ã‚‹ç›´è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã§ã™ã€‚

--- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã— ---
{headlines_text}
--- ã“ã“ã¾ã§ ---

ä¸Šè¨˜ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¸ã¾ãˆã€ã“ã®éŠ˜æŸ„ã®ä»Šå¾Œ1ã€œ2é€±é–“ã®æ ªä¾¡ã¸ã®å½±éŸ¿ã‚’
ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰ç›®ç·šã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

å¿…ãšä»¥ä¸‹ã® JSON å½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ãã‚Œä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚
{{"score": <1ã€œ5ã®æ•´æ•°>, "reason": "<50æ–‡å­—ä»¥å†…ã®æ—¥æœ¬èªã®ç†ç”±>"}}

ã‚¹ã‚³ã‚¢ã®åŸºæº–:
  1 = éå¸¸ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼ˆå¤§å¹…ä¸‹è½ãƒªã‚¹ã‚¯ï¼‰
  2 = ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼ˆä¸‹è½åœ§åŠ›ã‚ã‚Šï¼‰
  3 = ä¸­ç«‹ï¼ˆææ–™ä¹ã—ã„ / åˆ¤æ–­å›°é›£ï¼‰
  4 = ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼ˆä¸Šæ˜‡æœŸå¾…ã‚ã‚Šï¼‰
  5 = éå¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼ˆå¼·ã„ä¸Šæ˜‡ææ–™ï¼‰
"""


def _parse_gemini_response(text: str) -> dict:
    """
    Gemini ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ JSON ã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ã€‚
    å¿œç­”ã«ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã‚„ä½™è¨ˆãªãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹å ´åˆã‚‚å¯¾å¿œã™ã‚‹ã€‚

    Returns
    -------
    dict  {"score": int, "reason": str}  å¤±æ•—æ™‚ã¯ None
    """
    if not text:
        return None

    # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã®é™¤å»
    text = re.sub(r"```json\s*", "", text)
    text = re.sub(r"```\s*", "", text)
    text = text.strip()

    # JSON ãƒ–ãƒ­ãƒƒã‚¯ã®æŠ½å‡ºï¼ˆ{...} ã‚’æ¢ã™ï¼‰
    match = re.search(r"\{[^}]+\}", text, re.DOTALL)
    if not match:
        return None

    try:
        data = json.loads(match.group())
        score = int(data.get("score", 0))
        reason = str(data.get("reason", ""))[:50]
        if 1 <= score <= 5:
            return {"score": score, "reason": reason}
    except (json.JSONDecodeError, ValueError, TypeError):
        pass

    return None


def analyze_sentiment_gemini(
    ticker: str,
    headlines: list[str],
    api_key: str = None,
    model_name: str = None,
) -> dict:
    """
    Gemini API ã‚’ä½¿ã£ã¦éŠ˜æŸ„ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’åˆ¤å®šã™ã‚‹ã€‚

    Parameters
    ----------
    ticker : str
    headlines : list[str]
    api_key : str  çœç•¥æ™‚ã¯ config.GEMINI_API_KEY
    model_name : str  çœç•¥æ™‚ã¯ config.GEMINI_MODEL

    Returns
    -------
    dict  {"score": int, "reason": str}
    """
    if api_key is None:
        api_key = GEMINI_API_KEY
    if model_name is None:
        model_name = GEMINI_MODEL

    default_result = {"score": SENTIMENT_DEFAULT_SCORE, "reason": "åˆ¤å®šä¸èƒ½"}

    if genai is None:
        print(f"  [{ticker}] google-generativeai æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢")
        return default_result

    if not api_key:
        print(f"  [{ticker}] GEMINI_API_KEY æœªè¨­å®š â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢")
        return default_result

    if not headlines:
        return {"score": SENTIMENT_DEFAULT_SCORE, "reason": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã—"}

    # è¦‹å‡ºã—ã‚’æœ€å¤§ 20 ä»¶ã«åˆ¶é™ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ï¼‰
    headlines_trimmed = headlines[:20]
    headlines_text = "\n".join(f"ãƒ»{h}" for h in headlines_trimmed)

    prompt = _SENTIMENT_PROMPT_TEMPLATE.format(
        ticker=ticker,
        headlines_text=headlines_text,
    )

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=256,
            ),
        )
        raw_text = response.text
        result = _parse_gemini_response(raw_text)
        if result is not None:
            return result
        else:
            print(f"  [{ticker}] Gemini å¿œç­”ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {raw_text[:100]}")
            return default_result

    except Exception as e:
        print(f"  [{ticker}] Gemini API ã‚¨ãƒ©ãƒ¼: {e}")
        return default_result


# ====================================================================== #
#  3. ãƒ¡ã‚¤ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¢æ•°
# ====================================================================== #

def apply_sentiment_filter(
    candidates_df: pd.DataFrame,
    top_n: int = None,
    min_score: int = None,
    api_sleep: float = None,
) -> pd.DataFrame:
    """
    ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã«å¯¾ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã™ã‚‹ã€‚

    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
      1. prob_hybrid ä¸Šä½ top_n éŠ˜æŸ„ã‚’æŠ½å‡º
      2. å„éŠ˜æŸ„ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’å–å¾—
      3. Gemini API ã§ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ï¼ˆ1-5ï¼‰ã‚’åˆ¤å®š
      4. ã‚¹ã‚³ã‚¢ min_score ä»¥ä¸Šã®éŠ˜æŸ„ã®ã¿ã‚’è¿”ã™

    Parameters
    ----------
    candidates_df : pd.DataFrame
        screen_hybrid() ã®å‡ºåŠ›ã€‚columns ã« 'code', 'prob_hybrid' ã‚’å«ã‚€ã“ã¨ã€‚
    top_n : int
        ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æå¯¾è±¡ã®ä¸Šä½éŠ˜æŸ„æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.SENTIMENT_TOP_Nï¼‰
    min_score : int
        æœ€çµ‚é€šçŸ¥ã«æ®‹ã™æœ€ä½ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.SENTIMENT_MIN_SCOREï¼‰
    api_sleep : float
        Gemini API ã‚³ãƒ¼ãƒ«é–“ã®ã‚¹ãƒªãƒ¼ãƒ—ç§’æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.SENTIMENT_API_SLEEPï¼‰

    Returns
    -------
    pd.DataFrame
        ãƒ•ã‚£ãƒ«ã‚¿å¾Œã® DataFrameã€‚è¿½åŠ ã‚«ãƒ©ãƒ : sentiment_score, sentiment_reason
    """
    if top_n is None:
        top_n = SENTIMENT_TOP_N
    if min_score is None:
        min_score = SENTIMENT_MIN_SCORE
    if api_sleep is None:
        api_sleep = SENTIMENT_API_SLEEP

    if candidates_df.empty:
        print("ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: å…¥åŠ›ãŒç©ºã§ã™")
        return candidates_df

    # --- Step 1: ä¸Šä½ top_n éŠ˜æŸ„ã‚’æŠ½å‡º ---
    df = candidates_df.sort_values("prob_hybrid", ascending=False).head(top_n).copy()
    print(f"\n{'='*50}")
    print(f"[ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ] å¯¾è±¡: ä¸Šä½ {len(df)} éŠ˜æŸ„")
    print(f"{'='*50}")

    sentiment_scores = []
    sentiment_reasons = []

    for idx, row in df.iterrows():
        ticker = row["code"]
        print(f"\n--- {ticker} ---")

        # --- Step 2: ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾— ---
        try:
            headlines = fetch_news_rss(ticker)
            if headlines:
                print(f"  ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(headlines)} ä»¶å–å¾—")
                for h in headlines[:3]:
                    print(f"    â€¢ {h}")
                if len(headlines) > 3:
                    print(f"    ... ä»– {len(headlines) - 3} ä»¶")
            else:
                print(f"  ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢ {SENTIMENT_DEFAULT_SCORE}")
        except Exception as e:
            print(f"  ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            headlines = []

        # --- Step 3: Gemini ã§ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ¤å®š ---
        result = analyze_sentiment_gemini(ticker, headlines)
        score = result["score"]
        reason = result["reason"]
        sentiment_scores.append(score)
        sentiment_reasons.append(reason)

        emoji = {1: "ğŸ”´", 2: "ğŸŸ ", 3: "âšª", 4: "ğŸŸ¢", 5: "ğŸŸ¢ğŸŸ¢"}.get(score, "â“")
        print(f"  ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: {emoji} {score}/5 â€” {reason}")

        # --- Rate Limit é…æ…® ---
        if api_sleep > 0:
            time.sleep(api_sleep)

    df["sentiment_score"] = sentiment_scores
    df["sentiment_reason"] = sentiment_reasons

    # --- Step 4: ã‚¹ã‚³ã‚¢ã§ãƒ•ã‚£ãƒ«ã‚¿ ---
    filtered = df[df["sentiment_score"] >= min_score].copy()
    filtered = filtered.sort_values("prob_hybrid", ascending=False).reset_index(drop=True)

    print(f"\n{'='*50}")
    print(f"[ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æå®Œäº†]")
    print(f"  åˆ†æå¯¾è±¡: {len(df)} éŠ˜æŸ„")
    print(f"  ã‚¹ã‚³ã‚¢ {min_score} ä»¥ä¸Š: {len(filtered)} éŠ˜æŸ„")
    print(f"{'='*50}")

    return filtered


# ====================================================================== #
#  4. ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
# ====================================================================== #

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆscreen_hybrid ã®å‡ºåŠ›å½¢å¼ã‚’æ¨¡å€£ï¼‰
    dummy_df = pd.DataFrame({
        "code": ["7203.T", "6758.T", "9984.T", "8306.T", "6701.T"],
        "Close": [2500, 13000, 4300, 1800, 3900],
        "Volume": [5000000, 3000000, 29000000, 15000000, 11000000],
        "prob_global": [0.72, 0.68, 0.55, 0.50, 0.72],
        "prob_local": [0.85, 0.70, 0.99, 0.80, 0.81],
        "prob_hybrid": [0.77, 0.69, 0.73, 0.62, 0.76],
    })

    print("=== ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ãƒ†ã‚¹ãƒˆ ===")
    for ticker in dummy_df["code"][:2]:
        headlines = fetch_news_rss(ticker)
        print(f"{ticker}: {len(headlines)} ä»¶")
        for h in headlines[:3]:
            print(f"  â€¢ {h}")

    print("\n=== ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ãƒ†ã‚¹ãƒˆ ===")
    result = apply_sentiment_filter(dummy_df, top_n=5, min_score=4)
    if not result.empty:
        print(result.to_string(index=False))
    else:
        print("ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®éŠ˜æŸ„ãªã—")
